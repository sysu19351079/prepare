# 1.数学基础

## 1.微积分

### SGD,Momentum,Adagard,Adam原理

[参考](https://zhuanlan.zhihu.com/p/32626442)

参考回答：

SGD为随机梯度下降,每一次迭代计算数据集的mini-batch的梯度,然后对参数进行跟新。

Momentum参考了物理中动量的概念,前几次的梯度也会参与到当前的计算中,但是前几轮的梯度叠加在当前计算中会有一定的衰减。

Adagard在训练的过程中可以自动变更学习的速率,设置一个全局的学习率,而实际的学习率与以往的参数模和的开方成反比。

Adam利用梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率,在经过偏置的校正后,每一次迭代后的学习率都有个确定的范围,使得参数较为平稳。

![image-20221110171245722](C:%5CUsers%5CASUS%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20221110171245722.png)

![image-20221110172120777](C:%5CUsers%5CASUS%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20221110172120777.png)



### L1不可导的时候该怎么办

参考回答：

当损失函数不可导,梯度下降不再有效,可以使用坐标轴下降法,梯度下降是沿着当前点的负梯度方向进行参数更新,而坐标轴下降法是沿着坐标轴的方向,假设有m个特征个数,坐标轴下降法进参数更新的时候,先固定m-1个值,然后再求另外一个的局部最优解,从而避免损失函数不可导问题。

使用Proximal Algorithm对L1进行求解,此方法是去优化损失函数上界结果。



### sigmoid函数特性

![image-20221110172606588](C:%5CUsers%5CASUS%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20221110172606588.png)

![image-20221110172616469](C:%5CUsers%5CASUS%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20221110172616469.png)





## 2.统计学概论

### 切比雪夫不等式

![image-20221110172744278](C:%5CUsers%5CASUS%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20221110172744278.png)



### 极大似然估计

[详解最大似然估计（MLE）、最大后验概率估计（MAP），以及贝叶斯公式的理解](https://blog.csdn.net/u011508640/article/details/72815981)

极大似然估计，通俗理解来说，**就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值！**

**极大似然估计中采样需满足一个重要的假设，就是所有的采样都是独立同分布的。**

**极大似然估计**是频率学派模型参数估计的常用方法。含义是根据已知样本，希望通过调整模型参数来使得模型能够最大化样本情况出现的概率。

**最大后验概率估计（MAP）**是贝叶斯派模型参数估计的常用方法。她依然是根据已知样本，来通过调整模型参数使得模型能够产生该数据样本的概率最大，只不过对于模型参数有了一个先验假设，即模型参数可能满足某种分布，不再一味地依赖数据样例（万一数据量少或者数据不靠谱呢）。



### 频率学派和贝叶斯学派的区别

参考回答：

频率派认为抽样是无限的,在无限的抽样中,对于决策的规则可以很精确。贝叶斯派认为世界无时无刻不在改变,未知的变量和事件都有一定的概率,即后验概率是先验概率的修正。频率派认为模型参数是固定的,一个模型在无数次抽样后,参数是不变的。而贝叶斯学派认为数据才是固定的而参数并不是。频率派认为模型不存在先验而贝叶斯派认为模型存在先验。



## 3.线性代数

### 求m*k矩阵A和n*k矩阵的欧几里得距离?

![image-20221110180903413](C:%5CUsers%5CASUS%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5Cimage-20221110180903413.png)

[计算矩阵A与矩阵B的欧式距离](https://blog.csdn.net/Autism_/article/details/88360483)



# 2.机器学习算法

### 交叉熵公式

https://zhuanlan.zhihu.com/p/149186719

![img](https://pic3.zhimg.com/v2-eb0942fe8ab442af55d7fb01cc142efa_r.jpg)



### 逻辑回归

[逻辑回归（非常详细）](https://zhuanlan.zhihu.com/p/74874291)

[支持向量机 SVM（非常详细）](https://zhuanlan.zhihu.com/p/77750026)